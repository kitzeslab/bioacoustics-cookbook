{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Test performance of Bird species audio machine learning classifier on a human-labeled test set\n",
    "\n",
    "prepare python environment:\n",
    "\n",
    "```bash\n",
    "pip install opensoundscape==0.12.0 torch torchaudio torchvision timm\n",
    "pip install git+https://github.com/kitzeslab/bioacoustics-model-zoo\n",
    "pip install git+https://github.com/kitzeslab/name_conversions.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "def figsize(w,h):\n",
    "    plt.rcParams['figure.figsize']=[w,h]\n",
    "figsize(15,5) #for big visuals\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import bioacoustics_model_zoo as bmz\n",
    "import opensoundscape as opso\n",
    "import name_conversions # convert between bird species naming conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O annotation_Files.zip https://datadryad.org/stash/downloads/file_stream/641805\n",
    "!wget -O mp3_Files.zip https://datadryad.org/stash/downloads/file_stream/641807\n",
    "!unzip annotation_Files.zip -d ./Annotation_Files\n",
    "!unzip mp3_Files.zip -d ./Recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the current directory to where the dataset is downloaded\n",
    "# CHANGE THIS to your data path, eg '.' if downloaded with previous cell\n",
    "dataset_path = \".\"\n",
    "\n",
    "# make a list of all of the selection table files\n",
    "selections = glob(f\"{dataset_path}/Annotation_Files/*/*.txt\")\n",
    "\n",
    "# create a list of audio files, one corresponding to each Raven file\n",
    "# (Audio files have the same names as selection files with a different extension)\n",
    "audio_files = [\n",
    "    f.replace(\"Annotation_Files\", \"Recordings\").replace(\n",
    "        \".Table.1.selections.txt\", \".mp3\"\n",
    "    )\n",
    "    for f in selections\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SML161/miniconda3/envs/opso0110/lib/python3.11/site-packages/opensoundscape/annotations.py:300: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_annotations_df = pd.concat(all_file_dfs).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>annotation_file</th>\n",
       "      <th>annotation</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>low_f</th>\n",
       "      <th>high_f</th>\n",
       "      <th>Selection</th>\n",
       "      <th>View</th>\n",
       "      <th>Channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/SML161/labeled_datasets/pnre_ecy3329/Re...</td>\n",
       "      <td>/Users/SML161/labeled_datasets/pnre_ecy3329/An...</td>\n",
       "      <td>BTNW</td>\n",
       "      <td>0.913636</td>\n",
       "      <td>2.202273</td>\n",
       "      <td>4635.1</td>\n",
       "      <td>7439.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Spectrogram 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/SML161/labeled_datasets/pnre_ecy3329/Re...</td>\n",
       "      <td>/Users/SML161/labeled_datasets/pnre_ecy3329/An...</td>\n",
       "      <td>EATO</td>\n",
       "      <td>2.236363</td>\n",
       "      <td>2.693182</td>\n",
       "      <td>3051.9</td>\n",
       "      <td>4101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Spectrogram 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/SML161/labeled_datasets/pnre_ecy3329/Re...</td>\n",
       "      <td>/Users/SML161/labeled_datasets/pnre_ecy3329/An...</td>\n",
       "      <td>BTNW</td>\n",
       "      <td>4.234091</td>\n",
       "      <td>6.054545</td>\n",
       "      <td>4196.4</td>\n",
       "      <td>7477.2</td>\n",
       "      <td>3</td>\n",
       "      <td>Spectrogram 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/SML161/labeled_datasets/pnre_ecy3329/Re...</td>\n",
       "      <td>/Users/SML161/labeled_datasets/pnre_ecy3329/An...</td>\n",
       "      <td>EATO</td>\n",
       "      <td>5.870454</td>\n",
       "      <td>6.354545</td>\n",
       "      <td>2956.5</td>\n",
       "      <td>4101.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Spectrogram 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/SML161/labeled_datasets/pnre_ecy3329/Re...</td>\n",
       "      <td>/Users/SML161/labeled_datasets/pnre_ecy3329/An...</td>\n",
       "      <td>BHCO</td>\n",
       "      <td>6.877640</td>\n",
       "      <td>7.498095</td>\n",
       "      <td>6733.3</td>\n",
       "      <td>10376.5</td>\n",
       "      <td>5</td>\n",
       "      <td>Spectrogram 1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          audio_file  \\\n",
       "0  /Users/SML161/labeled_datasets/pnre_ecy3329/Re...   \n",
       "1  /Users/SML161/labeled_datasets/pnre_ecy3329/Re...   \n",
       "2  /Users/SML161/labeled_datasets/pnre_ecy3329/Re...   \n",
       "3  /Users/SML161/labeled_datasets/pnre_ecy3329/Re...   \n",
       "4  /Users/SML161/labeled_datasets/pnre_ecy3329/Re...   \n",
       "\n",
       "                                     annotation_file annotation  start_time  \\\n",
       "0  /Users/SML161/labeled_datasets/pnre_ecy3329/An...       BTNW    0.913636   \n",
       "1  /Users/SML161/labeled_datasets/pnre_ecy3329/An...       EATO    2.236363   \n",
       "2  /Users/SML161/labeled_datasets/pnre_ecy3329/An...       BTNW    4.234091   \n",
       "3  /Users/SML161/labeled_datasets/pnre_ecy3329/An...       EATO    5.870454   \n",
       "4  /Users/SML161/labeled_datasets/pnre_ecy3329/An...       BHCO    6.877640   \n",
       "\n",
       "   end_time   low_f   high_f Selection           View Channel  \n",
       "0  2.202273  4635.1   7439.0         1  Spectrogram 1       1  \n",
       "1  2.693182  3051.9   4101.0         2  Spectrogram 1       1  \n",
       "2  6.054545  4196.4   7477.2         3  Spectrogram 1       1  \n",
       "3  6.354545  2956.5   4101.0         4  Spectrogram 1       1  \n",
       "4  7.498095  6733.3  10376.5         5  Spectrogram 1       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_annotations = opso.BoxedAnnotations.from_raven_files(\n",
    "    selections, annotation_column=\"Species\", audio_files=audio_files\n",
    ")\n",
    "all_annotations.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the 4-letter codes used for annotations correspond to bird species names. These are called \"Alpha\" codes\n",
    "\n",
    "we can use name_conversions package to convert them to English common names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_annotations.df[\"annotation\"] = all_annotations.df[\"annotation\"].apply(\n",
    "    name_conversions.alpha_to_common\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create species presence/absence labels for each non-overlapping 3s audio clip (eta 20 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_labels = all_annotations.clip_labels(\n",
    "    clip_duration=3, clip_overlap=0, min_label_overlap=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of labels for each species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eastern Towhee                  4348\n",
       "Wood Thrush                     1773\n",
       "American Crow                   1662\n",
       "Northern Cardinal               1337\n",
       "Black-throated Green Warbler    1266\n",
       "Black-capped Chickadee          1075\n",
       "Tufted Titmouse                  917\n",
       "Ovenbird                         658\n",
       "Red-eyed Vireo                   456\n",
       "Common Yellowthroat              452\n",
       "Blue Jay                         422\n",
       "Scarlet Tanager                  419\n",
       "American Redstart                311\n",
       "Kentucky Warbler                 254\n",
       "Blue-gray Gnatcatcher            210\n",
       "Black-and-white Warbler          192\n",
       "Hermit Thrush                    172\n",
       "Blue-headed Vireo                161\n",
       "Brown-headed Cowbird             160\n",
       "Red-bellied Woodpecker           108\n",
       "Northern Flicker                 107\n",
       "Hooded Warbler                   101\n",
       "Yellow-billed Cuckoo              87\n",
       "Ruby-crowned Kinglet              65\n",
       "Louisiana Waterthrush             64\n",
       "Blue-winged Warbler               54\n",
       "Rose-breasted Grosbeak            47\n",
       "American Goldfinch                44\n",
       "American Robin                    39\n",
       "Carolina Wren                     35\n",
       "Swainson's Thrush                 31\n",
       "Wild Turkey                       20\n",
       "White-breasted Nuthatch           11\n",
       "Downy Woodpecker                   9\n",
       "Hairy Woodpecker                   6\n",
       "Veery                              5\n",
       "Bay-breasted Warbler               5\n",
       "Baltimore Oriole                   4\n",
       "Nashville Warbler                  4\n",
       "Chestnut-sided Warbler             4\n",
       "Canada Goose                       4\n",
       "Eastern Wood-Pewee                 3\n",
       "Red-winged Blackbird               2\n",
       "Common Raven                       2\n",
       "Red-shouldered Hawk                2\n",
       "Brown Creeper                      1\n",
       "Pileated Woodpecker                1\n",
       "Cedar Waxwing                      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_labels.sum(0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and apply a machine learning species classifier for bird sounds\n",
    "the first time you run this line, it will download the model files to your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model from URL...\n",
      "File hgnet1.ckpt already exists; skipping download.\n",
      "Loading model from local checkpoint /Users/SML161/nb_opso/preprocessing/hgnet1.ckpt...\n",
      "Downloading model from URL...\n",
      "File hgnet2.ckpt already exists; skipping download.\n",
      "Loading model from local checkpoint /Users/SML161/nb_opso/preprocessing/hgnet2.ckpt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SML161/miniconda3/envs/opso0110/lib/python3.11/site-packages/bioacoustics_model_zoo/hawkears/hawkears.py:198: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mdict = torch.load(model_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model from URL...\n",
      "File hgnet3.ckpt already exists; skipping download.\n",
      "Loading model from local checkpoint /Users/SML161/nb_opso/preprocessing/hgnet3.ckpt...\n",
      "Downloading model from URL...\n",
      "File hgnet4.ckpt already exists; skipping download.\n",
      "Loading model from local checkpoint /Users/SML161/nb_opso/preprocessing/hgnet4.ckpt...\n",
      "Downloading model from URL...\n",
      "File hgnet5.ckpt already exists; skipping download.\n",
      "Loading model from local checkpoint /Users/SML161/nb_opso/preprocessing/hgnet5.ckpt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SML161/miniconda3/envs/opso0110/lib/python3.11/site-packages/opensoundscape/ml/cnn.py:621: UserWarning: \n",
      "                    This architecture is not listed in opensoundscape.ml.cnn_architectures.ARCH_DICT.\n",
      "                    It will not be available for loading after saving the model with .save() (unless using pickle=True). \n",
      "                    To make it re-loadable, define a function that generates the architecture from arguments: (n_classes, n_channels) \n",
      "                    then use opensoundscape.ml.cnn_architectures.register_architecture() to register the generating function.\n",
      "\n",
      "                    The function can also set the returned object's .constructor_name to the registered string key in ARCH_DICT\n",
      "                    to avoid this warning and ensure it is reloaded correctly by opensoundscape.ml.load_model().\n",
      "\n",
      "                    See opensoundscape.ml.cnn_architectures module for examples of constructor functions\n",
      "                    \n",
      "  warnings.warn(\n",
      "/Users/SML161/miniconda3/envs/opso0110/lib/python3.11/site-packages/opensoundscape/ml/cnn.py:645: UserWarning: Failed to detect expected # input channels of this architecture.Make sure your architecture expects the number of channels equal to `channels` argument 1). Pytorch architectures generally expect 3 channels by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifier = bmz.HawkEars()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ask the classifier which species are present in the audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SML161/miniconda3/envs/opso0110/lib/python3.11/site-packages/opensoundscape/ml/cnn.py:1091: UserWarning: The columns of input samples df differ from `model.classes`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187d5c0bfdfc4a13a6450aadb8583c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = classifier.predict(clip_labels, batch_size=64, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class-averaged ROC AUC: 0.854\n",
      "class-averaged Average Precision: 0.447\n",
      "sample-averaged ROC AUC: 0.904\n",
      "sample-averaged Average Precision: 0.709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "print(\n",
    "    f\"class-averaged ROC AUC: {roc_auc_score(clip_labels.values, predictions[clip_labels.columns].values,average='macro'):.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"class-averaged Average Precision: {average_precision_score(clip_labels.values, predictions[clip_labels.columns].values, average='macro'):.3f}\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"sample-averaged ROC AUC: {roc_auc_score(clip_labels.values, predictions[clip_labels.columns].values,average='micro'):.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"sample-averaged Average Precision: {average_precision_score(clip_labels.values, predictions[clip_labels.columns].values, average='micro'):.3f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opso0110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
