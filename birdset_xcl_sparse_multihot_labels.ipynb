{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate a dataframe of sparse multi-hot clip labels for BirdSet XCL Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape import Audio, Spectrogram, CNN, BoxedAnnotations\n",
    "import opensoundscape as opso\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "def figsize(w,h):\n",
    "    plt.rcParams['figure.figsize']=[w,h]\n",
    "figsize(15,5) #for big visuals\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import datasets\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare and load the dataset\n",
    "\n",
    "If this is your first time using it, it will download all of xeno-canto! (Consider using smaller datasets or XC subset)\n",
    "\n",
    "For subsequent uses, just make sure to specify the same cache_dir so that it uses downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528422"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_dir = \"/home/kitzeslab/data/data_birdset/\"\n",
    "ds = datasets.load_dataset(\n",
    "    \"DBD-research-group/BirdSet\",\n",
    "    \"XCL\",\n",
    "    trust_remote_code=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "t = ds[\"train\"]\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to create the training table depends on how we want to sample clips from XC files\n",
    "\n",
    "for this example, we will create one clip for each of the detected events. If there are no detected events, we will use the beginning of the audio file. We use only up to the first 5 events maximum (random sample may be better). We use the start time of the event as the start time of the audio clip - center or random may be better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_duration = 3\n",
    "max_events = 5\n",
    "\n",
    "records = []\n",
    "for i in tqdm(range(len(t))):\n",
    "    file = t[i]\n",
    "    # optionally, filter by quality rating or other metadata\n",
    "    # if file['quality'] not in ['A','B']:\n",
    "    #     continue\n",
    "    detected_events = file[\"detected_events\"].copy()\n",
    "\n",
    "    if len(detected_events) < 1:\n",
    "        # no detections: use beginning of audio file\n",
    "        detected_events = [[0, clip_duration]]\n",
    "    elif len(detected_events) > max_events:\n",
    "        # use up to 5 first\n",
    "        detected_events = file[\"detected_events\"][:max_events]\n",
    "\n",
    "    for j, (start, end) in enumerate(detected_events):\n",
    "        record = {\n",
    "            \"file\": file[\"filepath\"],\n",
    "            \"start_time\": start,\n",
    "            \"annotation\": file[\"ebird_code\"],\n",
    "        }\n",
    "        records.append(record)\n",
    "    # break\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# convert integer annotation to list of one annotation per row\n",
    "# this is the format used by annotations.categorical_to_multi_hot\n",
    "df[\"annotation_list\"] = [[x] for x in df[\"annotation\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a sparse multi-hot label array of clip x class presence (1) / absence (0) (mostly 0s, sparse array efficiently stores 1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape import annotations\n",
    "\n",
    "multihot_labels_sparse, classes = annotations.categorical_to_multi_hot(\n",
    "    df[\"annotation_list\"], sparse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert integer labels to ebird codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buwtea'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebird_classes = [\n",
    "    t.info.features[\"ebird_code_multilabel\"].feature.int2str(c) for c in classes\n",
    "]\n",
    "ebird_classes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a spare dataframe and save to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame.sparse.from_spmatrix(\n",
    "    multihot_labels_sparse,\n",
    "    index=pd.MultiIndex.from_frame(df[[\"file\", \"start_time\"]]),\n",
    "    columns=ebird_classes,\n",
    ")\n",
    "# saved pickle is 103 MB, not bad for df of shape (1991469, 9734) with file paths\n",
    "labels.to_pickle(f\"{cache_dir}/xcl_train_sparse_multihot_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to use the labels in OpenSoundscape later: load the pickle and add the \"end_time\" index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_pickle(f\"{cache_dir}/xcl_train_sparse_multihot_labels.pkl\")\n",
    "\n",
    "# add in \"end time\" to the index, which is simply start time + clip duration in our case\n",
    "labels[\"end_time\"] = labels.index.get_level_values(\"start_time\") + clip_duration\n",
    "labels = labels.reset_index().set_index([\"file\", \"start_time\", \"end_time\"])\n",
    "labels.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opso0110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
