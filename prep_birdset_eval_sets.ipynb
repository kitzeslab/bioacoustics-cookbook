{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate a dataframe of sparse multi-hot clip labels for BirdSet evaluation sets\n",
    "format will be a bit different than XCL training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensoundscape import Audio, Spectrogram, CNN, BoxedAnnotations\n",
    "import opensoundscape as opso\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "def figsize(w,h):\n",
    "    plt.rcParams['figure.figsize']=[w,h]\n",
    "figsize(15,5) #for big visuals\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import datasets\n",
    "from tqdm.autonotebook import tqdm\n",
    "from opensoundscape import annotations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare and load the dataset\n",
    "\n",
    "If this is your first time using it, it will download all of xeno-canto! (Consider using smaller datasets or XC subset)\n",
    "\n",
    "For subsequent uses, just make sure to specify the same cache_dir so that it uses downloaded files\n",
    "\n",
    "\n",
    "note that we are assuming the only annotated files are files that have >=1 annotation in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['PER','NES','UHH','HSN','NBP','SSW','SNE','POW']#,'VOX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/home/kitzeslab/data/data_birdset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset PER\n",
      "Processing dataset NES\n",
      "Processing dataset UHH\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    print(f\"Processing dataset {dataset_name}\")\n",
    "    ds = datasets.load_dataset(\n",
    "        \"DBD-research-group/BirdSet\",\n",
    "        dataset_name,\n",
    "        trust_remote_code=True,\n",
    "        cache_dir=cache_dir,\n",
    "    )\n",
    "    classes = ds['test'].info.features['ebird_code'].names\n",
    "    l=ds['test'].info.features['ebird_code']\n",
    "\n",
    "    # aggregate bounding box annotations into a DataFrame\n",
    "    records = []\n",
    "    for i in range(len(ds[\"test\"])):\n",
    "        info= ds[\"test\"][i]\n",
    "        records.append({\n",
    "            'audio_file':info['filepath'],\n",
    "            'start_time': info['start_time'],\n",
    "            'end_time': info['end_time'],\n",
    "            'low_f': info['low_freq'],\n",
    "            'high_f': info['high_freq'],\n",
    "            'int_label': info['ebird_code'],\n",
    "            'annotation': l.int2str(info['ebird_code']),\n",
    "        })\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv(f\"{cache_dir}/{dataset_name}_test_bbox.csv\", index=False)\n",
    "\n",
    "    \n",
    "    # create labels on 3s and 5s non-overlapping clips\n",
    "    ba = annotations.BoxedAnnotations(df,audio_files=df['audio_file'].unique())\n",
    "    labels = ba.clip_labels(clip_duration=3,min_label_overlap=0.25,class_subset=classes,return_type='CategoricalLabels')\n",
    "    labels_sparse_df = labels.multihot_df(sparse=True)\n",
    "    labels_sparse_df.to_pickle(f\"{cache_dir}/{dataset_name}_test_multihot_3s.pkl\")\n",
    "\n",
    "    ba = annotations.BoxedAnnotations(df,audio_files=df['audio_file'].unique())\n",
    "    labels = ba.clip_labels(clip_duration=5,min_label_overlap=0.25,class_subset=classes,return_type='CategoricalLabels')\n",
    "    labels_sparse_df = labels.multihot_df(sparse=True)\n",
    "    labels_sparse_df.to_pickle(f\"{cache_dir}/{dataset_name}_test_multihot_5s.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to use the labels in OpenSoundscape later: load the pickle\n",
    "```python\n",
    "labels = pd.read_pickle(f\"{cache_dir}/POW_test_multihot_3s.pkl\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opso0110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
